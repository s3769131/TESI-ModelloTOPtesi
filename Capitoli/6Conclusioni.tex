% !TEX encoding = utf8
% !TEX root = ../main.tex


\chapter{Conclusioni}
\label{cap:conclusioni}

In questa tesi si è affrontato il problema della classificazione di immagini ad alta risoluzione (VHRI), con una particolare attenzione al contributo che l'estrazione di \emph{feature} aggiuntive può apportare all'accuratezza dei risultati ottenuti sulle mappe di classificazione.
In particolare è stato analizzato e implementato l'algoritmo HOG, testandone l'applicabilità al problema della mappatura del suolo da immagini multispettrali telerilevate.\\
Nella parte di sperimentazione sono stati presentati tre casi di studio, in cui l'eterogeneità spaziale e spettrale delle immagini coinvolte ha reso difficoltosa la classificazione. In particolare, confrontando i parametri di precisione ottenuti con e senza estrazione di \emph{feature}, si è potuto constatare come l'utilizzo dell'algoritmo HOG abbia spesso portato un incremento di accuratezza, soprattutto per  quelle  classi dove è marcata la presenza di strutture geometriche regolari. Quest'approccio ha invece mostrato i suoi limiti nella mappatura di aree spazialmente omogenee.\\
Per queste ragioni, nei casi di studio in ambito urbano, le \emph{feature} di tessitura HOG sono molto soddisfacenti per quelle zone caratterizzate da un elevato livello di dettaglio e geometricità, mentre è consigliabile affiancare altri metodi di \emph{feature extraction} per classificare con affidabilità porzioni di suolo strutturalmente omogenee.\\
In generale, spazi delle \emph{feature} ad alta dimensionalità hanno reso possibile la discriminazione di classi con differenze anche molto sottili con un elevato livello di dettaglio. Tuttavia, volumi così alti hanno fatto sì che ottenere livelli di precisione adeguata sulle numerose classi in gioco  fosse una ardua sfida. Al crescere della dimensione dello spazio delle \emph{feature} aumenta, infatti, anche il numero di parametri del classificatore, rendendo il numero dei pixel di training (che è fissato dal particolare \emph{dataset}) insufficienti ad effettuare stime accettabili. Questo è emerso dai numerosi risultati ottenuti, dove si è potuto osservare che a classi aventi un numero di pixel di training limitati sono corrisposti valori di PA estremamente bassi.  Si deve tener conto che  il numero dei campioni di training necessari ad addestrare un classificatore con dati ad alta dimensionalità è molto più grande di quello per dati convenzionali. In quest'ottica la limitata disponibilità di informazione del \emph{training set}, dovuta al fatto che ottenere questi campioni è difficile e costoso,  porta a problematiche non trascurabili per quanto riguarda i parametri di accuratezza.\\
In conclusione quindi, possibili miglioramenti dell'algoritmo proposto possono essere ottenuti tramite la riduzione del numero di \emph{feature} utilizzate (\emph{feature reduction}). Questa può  essere ottenuta sia mediante tecniche che identificano un opportuno sottoinsieme dei parametri disponibili (\emph{feature selection}), sia trasformando lo spazio $d$-dimensionale  in uno spazio a dimensione minore tramite una funzione che minimizzi la relativa perdita di informazione (\emph{feature extraction}).